{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Personalized Text-to-Image Generator\n",
        "Google Colab Pro access is required for running this notebook as atleast one A100 GPU is required to run the training and inference scripts."
      ],
      "metadata": {
        "id": "rpe81XKu2n4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing conda on the Colab environment**"
      ],
      "metadata": {
        "id": "HiZC2rbdhs6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ9Zyzds4Mix",
        "outputId": "93e4b69f-829b-449f-c4e7-c031946c984e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:09\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the drive which will contain the code repository and the set of reference images. The code repository should be uploaded to the google drive of the account, you are using google colab from."
      ],
      "metadata": {
        "id": "dINH2Nk4iMpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5mf4Xx2qiz4",
        "outputId": "6de35b17-2df3-45fa-f953-0510a3a4b575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2ZWfeeDqjAh",
        "outputId": "afbffc89-d8f0-4983-8b08-5368a66b421a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a conda environment, that will contain all the installed dependencies required for the model to run, using the environment.yaml file."
      ],
      "metadata": {
        "id": "PFJq4QK4ilC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda remove --name vico --all\n",
        "!conda env create -f environment.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skBlwTbm3H69",
        "outputId": "498fcc72-0c39-4272-8d3d-2e5c90795ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Remove all packages in environment /usr/local/envs/vico:\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/vico\n",
            "\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  _libgcc_mutex-0.1-conda_forge\n",
            "  _openmp_mutex-4.5-2_kmp_llvm\n",
            "  blas-1.0-mkl\n",
            "  bzip2-1.0.8-h5eee18b_5\n",
            "  ca-certificates-2023.12.12-h06a4308_0\n",
            "  cudatoolkit-11.3.1-h2bc3f7f_2\n",
            "  ffmpeg-4.3-hf484d3e_0\n",
            "  freetype-2.12.1-h4a9f257_0\n",
            "  gmp-6.2.1-h295c915_3\n",
            "  gnutls-3.6.15-he1e5248_0\n",
            "  jpeg-9e-h5eee18b_1\n",
            "  lame-3.100-h7b6447c_0\n",
            "  lcms2-2.12-h3be6417_0\n",
            "  ld_impl_linux-64-2.38-h1181459_1\n",
            "  lerc-3.0-h295c915_0\n",
            "  libdeflate-1.17-h5eee18b_1\n",
            "  libffi-3.3-he6710b0_2\n",
            "  libgcc-ng-13.2.0-h807b86a_5\n",
            "  libiconv-1.16-h7f8727e_2\n",
            "  libidn2-2.3.4-h5eee18b_0\n",
            "  libpng-1.6.39-h5eee18b_0\n",
            "  libstdcxx-ng-11.2.0-h1234567_1\n",
            "  libtasn1-4.19.0-h5eee18b_0\n",
            "  libtiff-4.5.1-h6a678d5_0\n",
            "  libunistring-0.9.10-h27cfd23_0\n",
            "  libuv-1.44.2-h5eee18b_0\n",
            "  libwebp-base-1.3.2-h5eee18b_0\n",
            "  libzlib-1.2.13-hd590300_5\n",
            "  llvm-openmp-17.0.6-h4dfa4b3_0\n",
            "  lz4-c-1.9.4-h6a678d5_0\n",
            "  mkl-2023.2.0-h84fe81f_50496\n",
            "  mkl-service-2.4.0-py38h5eee18b_1\n",
            "  mkl_fft-1.3.8-py38h5eee18b_0\n",
            "  mkl_random-1.2.4-py38hdb19cb5_0\n",
            "  ncurses-6.4-h6a678d5_0\n",
            "  nettle-3.7.3-hbbd107a_1\n",
            "  numpy-1.22.3-py38hf6e8229_2\n",
            "  numpy-base-1.22.3-py38h060ed82_2\n",
            "  openh264-2.1.1-h4ff587b_0\n",
            "  openjpeg-2.4.0-h3ad879b_0\n",
            "  openssl-1.1.1w-h7f8727e_0\n",
            "  pillow-10.2.0-py38h5eee18b_0\n",
            "  pip-20.3.3-py38h06a4308_0\n",
            "  python-3.8.10-h12debd9_8\n",
            "  pytorch-1.10.2-py3.8_cuda11.3_cudnn8.2.0_0\n",
            "  pytorch-mutex-1.0-cuda\n",
            "  readline-8.2-h5eee18b_0\n",
            "  setuptools-68.2.2-py38h06a4308_0\n",
            "  sqlite-3.41.2-h5eee18b_0\n",
            "  tbb-2021.8.0-hdb19cb5_0\n",
            "  tk-8.6.12-h1ccaba5_0\n",
            "  torchvision-0.11.3-py38_cu113\n",
            "  typing_extensions-4.9.0-py38h06a4308_1\n",
            "  wheel-0.41.2-py38h06a4308_0\n",
            "  xz-5.4.6-h5eee18b_0\n",
            "  zlib-1.2.13-hd590300_5\n",
            "  zstd-1.5.5-hc292b87_0\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Channels:\n",
            " - pytorch\n",
            " - defaults\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 23.11.0\n",
            "    latest version: 24.1.2\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Installing pip dependencies: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/vico/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Obtaining taming-transformers from git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers (from -r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 17))\n",
            "  Updating ./src/taming-transformers clone (to revision master)\n",
            "Obtaining clip from git+https://github.com/openai/CLIP.git@main#egg=clip (from -r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 18))\n",
            "  Updating ./src/clip clone (to revision main)\n",
            "Obtaining file:///content/drive/MyDrive/Personalized-text-to-image-generator (from -r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 19))\n",
            "Requirement already satisfied: torch in /usr/local/envs/vico/lib/python3.8/site-packages (from clip->-r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 18)) (1.10.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/envs/vico/lib/python3.8/site-packages (from clip->-r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 18)) (0.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/vico/lib/python3.8/site-packages (from latent-diffusion==0.0.1->-r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 19)) (1.22.3)\n",
            "Collecting albumentations==1.1.0\n",
            "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
            "Collecting einops==0.4.1\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting imageio==2.14.1\n",
            "  Downloading imageio-2.14.1-py3-none-any.whl (3.3 MB)\n",
            "Collecting imageio-ffmpeg==0.4.7\n",
            "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "Collecting kornia==0.6\n",
            "  Downloading kornia-0.6.0-py2.py3-none-any.whl (367 kB)\n",
            "Collecting omegaconf==2.1.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "Collecting opencv-python==4.2.0.34\n",
            "  Downloading opencv_python-4.2.0.34-cp38-cp38-manylinux1_x86_64.whl (28.2 MB)\n",
            "Collecting pillow==9.0.1\n",
            "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Collecting pudb==2019.2\n",
            "  Downloading pudb-2019.2.tar.gz (59 kB)\n",
            "Collecting pytorch-lightning==1.5.9\n",
            "  Downloading pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/vico/lib/python3.8/site-packages (from pytorch-lightning==1.5.9->-r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 6)) (4.9.0)\n",
            "Collecting torch-fidelity==0.3.0\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Collecting torchmetrics==0.6.0\n",
            "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "Collecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting streamlit>=0.73.1\n",
            "  Downloading streamlit-1.32.0-py2.py3-none-any.whl (8.1 MB)\n",
            "Collecting test-tube>=0.7.5\n",
            "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
            "Collecting altair<6,>=4.0\n",
            "  Downloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
            "Collecting blinker<2,>=1.0.0\n",
            "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting cachetools<6,>=4.0\n",
            "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
            "Collecting click<9,>=7.0\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "Collecting jsonschema>=3.0\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "Collecting importlib-resources>=1.4.0\n",
            "  Downloading importlib_resources-6.1.3-py3-none-any.whl (34 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "Collecting packaging\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Collecting pandas<3,>=1.3.0\n",
            "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "Collecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting protobuf<5,>=3.20\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Collecting pyarrow>=7.0\n",
            "  Downloading pyarrow-15.0.1-cp38-cp38-manylinux_2_28_x86_64.whl (38.4 MB)\n",
            "Collecting pydeck<1,>=0.8.0b4\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "Collecting jinja2\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Collecting pygments>=1.0\n",
            "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
            "Collecting qudida>=0.0.4\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Collecting referencing>=0.28.4\n",
            "  Downloading referencing-0.33.0-py3-none-any.whl (26 kB)\n",
            "Collecting regex\n",
            "  Downloading regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
            "Collecting rich<14,>=10.14.0\n",
            "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Downloading rpds_py-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting scikit-image>=0.16.1\n",
            "  Downloading scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
            "  Downloading scikit_image-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "Collecting lazy_loader>=0.1\n",
            "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
            "Collecting networkx>=2.8\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "Collecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "Collecting scikit-learn>=0.19.1\n",
            "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting tenacity<9,>=8.1.0\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Collecting tensorboard>=2.2.0\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/envs/vico/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.9->-r /content/drive/MyDrive/Personalized-text-to-image-generator/condaenv.9udfqofd.requirements.txt (line 6)) (0.41.2)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.28.2-py2.py3-none-any.whl (186 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting grpcio>=1.48.2\n",
            "  Downloading grpcio-1.62.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-7.0.2-py3-none-any.whl (24 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.4.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
            "Collecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "Collecting toml<2,>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tornado<7,>=6.0.3\n",
            "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Collecting urwid>=1.1.1\n",
            "  Downloading urwid-2.6.8-py3-none-any.whl (295 kB)\n",
            "Collecting watchdog>=2.1.5\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (308 kB)\n",
            "Collecting zipp>=3.1.0\n",
            "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "Collecting toolz\n",
            "  Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "Building wheels for collected packages: pudb, antlr4-python3-runtime, test-tube\n",
            "  Building wheel for pudb (setup.py): started\n",
            "  Building wheel for pudb (setup.py): finished with status 'done'\n",
            "  Created wheel for pudb: filename=pudb-2019.2-py3-none-any.whl size=63214 sha256=77c047e227f1aff78921661f9947c9666664302370a9b688856c9bf5c7f61313\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/83/f1/d8a09d401e2512bfda01ac9fc1b334885f9ddf51617c1c49f1\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141209 sha256=dbb4bf080fd7353d1da83863e8bda98d447c077522dceb8e3bfd41cb7c91d31a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "  Building wheel for test-tube (setup.py): started\n",
            "  Building wheel for test-tube (setup.py): finished with status 'done'\n",
            "  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25327 sha256=b2803bc65bdbe79295396f617ab08e2db5a1682de2bbd8fa3f723a63f5d6f20c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b0/3a/00ea66dbb0d9ce470ce1bdcb854a6fa030c279c316cb27ca9e\n",
            "Successfully built pudb antlr4-python3-runtime test-tube\n",
            "Installing collected packages: zipp, urllib3, rpds-py, pyasn1, idna, charset-normalizer, certifi, attrs, six, rsa, requests, referencing, pyasn1-modules, oauthlib, multidict, importlib-resources, frozenlist, cachetools, yarl, tzdata, threadpoolctl, smmap, scipy, requests-oauthlib, pytz, python-dateutil, pkgutil-resolve-name, pillow, mdurl, MarkupSafe, jsonschema-specifications, joblib, importlib-metadata, google-auth, async-timeout, aiosignal, werkzeug, wcwidth, tqdm, toolz, tifffile, tensorboard-data-server, setuptools, scikit-learn, regex, PyYAML, PyWavelets, pygments, protobuf, pandas, packaging, opencv-python-headless, networkx, markdown-it-py, markdown, lazy-loader, jsonschema, jinja2, imageio, grpcio, google-auth-oauthlib, gitdb, fsspec, filelock, click, aiohttp, absl-py, watchdog, urwid, tornado, torchmetrics, toml, tokenizers, tensorboard, tenacity, scikit-image, sacremoses, rich, qudida, pyDeprecate, pydeck, pyarrow, huggingface-hub, gitpython, future, ftfy, blinker, antlr4-python3-runtime, altair, transformers, torch-fidelity, test-tube, taming-transformers, streamlit, pytorch-lightning, pudb, opencv-python, omegaconf, latent-diffusion, kornia, imageio-ffmpeg, einops, clip, albumentations\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 10.2.0\n",
            "    Uninstalling pillow-10.2.0:\n",
            "      Successfully uninstalled pillow-10.2.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 68.2.2\n",
            "    Uninstalling setuptools-68.2.2:\n",
            "      Successfully uninstalled setuptools-68.2.2\n",
            "  Running setup.py develop for taming-transformers\n",
            "  Running setup.py develop for latent-diffusion\n",
            "  Running setup.py develop for clip\n",
            "Successfully installed MarkupSafe-2.1.5 PyWavelets-1.4.1 PyYAML-6.0.1 absl-py-2.1.0 aiohttp-3.9.3 aiosignal-1.3.1 albumentations-1.1.0 altair-5.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.3 attrs-23.2.0 blinker-1.7.0 cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 clip einops-0.4.1 filelock-3.13.1 frozenlist-1.4.1 fsspec-2024.2.0 ftfy-6.1.3 future-1.0.0 gitdb-4.0.11 gitpython-3.1.42 google-auth-2.28.2 google-auth-oauthlib-1.0.0 grpcio-1.62.1 huggingface-hub-0.21.4 idna-3.6 imageio-2.14.1 imageio-ffmpeg-0.4.7 importlib-metadata-7.0.2 importlib-resources-6.1.3 jinja2-3.1.3 joblib-1.3.2 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 kornia-0.6.0 latent-diffusion lazy-loader-0.3 markdown-3.5.2 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.5 networkx-3.1 oauthlib-3.2.2 omegaconf-2.1.1 opencv-python-4.2.0.34 opencv-python-headless-4.9.0.80 packaging-23.2 pandas-2.0.3 pillow-9.0.1 pkgutil-resolve-name-1.3.10 protobuf-4.25.3 pudb-2019.2 pyDeprecate-0.3.1 pyarrow-15.0.1 pyasn1-0.5.1 pyasn1-modules-0.3.0 pydeck-0.8.1b0 pygments-2.17.2 python-dateutil-2.9.0.post0 pytorch-lightning-1.5.9 pytz-2024.1 qudida-0.0.4 referencing-0.33.0 regex-2023.12.25 requests-2.31.0 requests-oauthlib-1.4.0 rich-13.7.1 rpds-py-0.18.0 rsa-4.9 sacremoses-0.1.1 scikit-image-0.20.0 scikit-learn-1.3.2 scipy-1.9.1 setuptools-59.5.0 six-1.16.0 smmap-5.0.1 streamlit-1.32.0 taming-transformers tenacity-8.2.3 tensorboard-2.14.0 tensorboard-data-server-0.7.2 test-tube-0.7.5 threadpoolctl-3.3.0 tifffile-2023.7.10 tokenizers-0.12.1 toml-0.10.2 toolz-0.12.1 torch-fidelity-0.3.0 torchmetrics-0.6.0 tornado-6.4 tqdm-4.66.2 transformers-4.18.0 tzdata-2024.1 urllib3-2.2.1 urwid-2.6.8 watchdog-4.0.0 wcwidth-0.2.13 werkzeug-3.0.1 yarl-1.9.4 zipp-3.17.0\n",
            "\n",
            "\b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate vico\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "# conda environments:\n",
            "#\n",
            "base                     /usr/local\n",
            "vico                     /usr/local/envs/vico\n",
            "\n",
            "configs  environment.yaml  images\t\t      logs     models\t    README.md  setup.py\n",
            "data\t evaluation\t   latent_diffusion.egg-info  main.py  __pycache__  scripts    src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps for running the training script\n",
        "\n",
        "ACTUAL_RESUME: path where the pre-trained stable-diffusion model is saved.\n",
        "DATA-ROOT: path to the folder containing a set of reference images\n",
        "GPUS: list of indices of the GPUs you want to train on, separated by commas. For example, we have used a single GPU to train the model, so we provided the variable as â€“gpus 0,\n",
        "INIT-WORD: word that generally describes the subject. Eg: Toy, Dog\n",
        "\n",
        "**Activating the environment vico and running the training on a set of reference images.**"
      ],
      "metadata": {
        "id": "zcfh9A_dkHws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /usr/local/bin/activate vico && python main.py \\\n",
        "--base configs/v1-finetune.yaml -t \\\n",
        "--actual_resume models/stable-diffusion-v1/sd-v1-4.ckpt \\\n",
        "-n \"\" \\\n",
        "--gpus 0, \\\n",
        "--data_root images/ollie \\\n",
        "--init_word \"dog\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BOtbFFk9_gT",
        "outputId": "fc883615-c691-4c8c-c950-2c4b25687670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 23\n",
            "Running on GPUs 0,\n",
            "Loading model from models/stable-diffusion-v1/sd-v1-4.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 910.77 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'logit_scale', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'visual_projection.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'text_projection.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Restored from models/stable-diffusion-v1/sd-v1-4.ckpt with 80 missing and 2 unexpected keys\n",
            "Missing Keys: ['model.diffusion_model.output_blocks.4.1.image_cross_attention.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.norm1.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.norm1.bias', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.norm2.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.norm2.bias', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.norm3.weight', 'model.diffusion_model.output_blocks.4.1.image_cross_attention.norm3.bias', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.norm1.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.norm1.bias', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.norm2.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.norm2.bias', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.norm3.weight', 'model.diffusion_model.output_blocks.6.1.image_cross_attention.norm3.bias', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.norm1.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.norm1.bias', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.norm2.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.norm2.bias', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.norm3.weight', 'model.diffusion_model.output_blocks.8.1.image_cross_attention.norm3.bias', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.norm1.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.norm1.bias', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.norm2.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.norm2.bias', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.norm3.weight', 'model.diffusion_model.output_blocks.10.1.image_cross_attention.norm3.bias']\n",
            "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']\n",
            "CLIP text encoder Total:123.06M Trainable:0.00M\n",
            "UNet + ImageCA Total:910.77M Trainable:51.25M\n",
            "Embedding manager Total:0.00M Trainable:0.00M\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/loggers/test_tube.py:104: LightningDeprecationWarning: The TestTubeLogger is deprecated since v1.5 and will be removed in v1.7. We recommend switching to the `pytorch_lightning.loggers.TensorBoardLogger` as an alternative.\n",
            "  rank_zero_deprecation(\n",
            "Monitoring val/loss_simple_ema as checkpoint metric.\n",
            "Merged modelckpt-cfg: \n",
            "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/ollie2024-03-12T18-36-55_v1-finetune/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 1, 'every_n_train_steps': 50}}\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='ddp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='ddp')` instead.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "#### Data #####\n",
            "train, PersonalizedBase, 800\n",
            "validation, PersonalizedBase, 8\n",
            "accumulate_grad_batches = 1\n",
            "Setting learning rate to 5.00e-03 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 1 (batchsize) * 5.00e-03 (base_lr)\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:275: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "  rank_zero_deprecation(\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:284: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
            "  rank_zero_deprecation(\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:291: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
            "  rank_zero_deprecation(\n",
            "Global seed set to 23\n",
            "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "We are optimizing both text embeddings and CA!\n",
            "Project config\n",
            "model:\n",
            "  base_learning_rate: 0.005\n",
            "  target: models.diffusion.ddpm.LatentDiffusion\n",
            "  params:\n",
            "    linear_start: 0.00085\n",
            "    linear_end: 0.012\n",
            "    num_timesteps_cond: 1\n",
            "    log_every_t: 200\n",
            "    timesteps: 1000\n",
            "    first_stage_key: image\n",
            "    cond_stage_key: caption\n",
            "    image_size: 64\n",
            "    channels: 4\n",
            "    cond_stage_trainable: true\n",
            "    conditioning_key: crossattn\n",
            "    monitor: val/loss_simple_ema\n",
            "    scale_factor: 0.18215\n",
            "    use_ema: false\n",
            "    embedding_reg_weight: 0.0\n",
            "    unfreeze_model: false\n",
            "    model_lr: 0.0\n",
            "    personalization_config:\n",
            "      target: models.modules.embedding_manager.EmbeddingManager\n",
            "      params:\n",
            "        placeholder_strings:\n",
            "        - '*'\n",
            "        initializer_words:\n",
            "        - dog\n",
            "        per_image_tokens: false\n",
            "        num_vectors_per_token: 1\n",
            "        progressive_words: false\n",
            "        embedding_manager_ckpt: ''\n",
            "    unet_config:\n",
            "      target: models.modules.diffusionmodules.openaimodel.UNetModel\n",
            "      params:\n",
            "        image_size: 32\n",
            "        in_channels: 4\n",
            "        out_channels: 4\n",
            "        model_channels: 320\n",
            "        attention_resolutions:\n",
            "        - 4\n",
            "        - 2\n",
            "        - 1\n",
            "        num_res_blocks: 2\n",
            "        channel_mult:\n",
            "        - 1\n",
            "        - 2\n",
            "        - 4\n",
            "        - 4\n",
            "        num_heads: 8\n",
            "        use_spatial_transformer: true\n",
            "        transformer_depth: 1\n",
            "        context_dim: 768\n",
            "        use_checkpoint: true\n",
            "        legacy: false\n",
            "    first_stage_config:\n",
            "      target: models.autoencoder.AutoencoderKL\n",
            "      params:\n",
            "        embed_dim: 4\n",
            "        monitor: val/rec_loss\n",
            "        ddconfig:\n",
            "          double_z: true\n",
            "          z_channels: 4\n",
            "          resolution: 512\n",
            "          in_channels: 3\n",
            "          out_ch: 3\n",
            "          ch: 128\n",
            "          ch_mult:\n",
            "          - 1\n",
            "          - 2\n",
            "          - 4\n",
            "          - 4\n",
            "          num_res_blocks: 2\n",
            "          attn_resolutions: []\n",
            "          dropout: 0.0\n",
            "        lossconfig:\n",
            "          target: torch.nn.Identity\n",
            "    cond_stage_config:\n",
            "      target: models.modules.encoders.modules.FrozenCLIPEmbedder\n",
            "    ckpt_path: models/stable-diffusion-v1/sd-v1-4.ckpt\n",
            "data:\n",
            "  target: main.DataModuleFromConfig\n",
            "  params:\n",
            "    batch_size: 1\n",
            "    num_workers: 0\n",
            "    wrap: false\n",
            "    train:\n",
            "      target: data.personalized.PersonalizedBase\n",
            "      params:\n",
            "        size: 512\n",
            "        set: train\n",
            "        per_image_tokens: false\n",
            "        repeats: 100\n",
            "    validation:\n",
            "      target: data.personalized.PersonalizedBase\n",
            "      params:\n",
            "        size: 512\n",
            "        set: val\n",
            "        per_image_tokens: false\n",
            "        repeats: 10\n",
            "\n",
            "Lightning config\n",
            "modelcheckpoint:\n",
            "  params:\n",
            "    every_n_train_steps: 50\n",
            "callbacks:\n",
            "  image_logger:\n",
            "    target: main.ImageLogger\n",
            "    params:\n",
            "      batch_frequency: 50\n",
            "      max_images: 1\n",
            "      increase_log_steps: false\n",
            "trainer:\n",
            "  benchmark: true\n",
            "  max_steps: 510\n",
            "  accelerator: ddp\n",
            "  gpus: 0,\n",
            "\n",
            "\n",
            "  | Name              | Type               | Params\n",
            "---------------------------------------------------------\n",
            "0 | model             | DiffusionWrapper   | 910 M \n",
            "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
            "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
            "3 | embedding_manager | EmbeddingManager   | 1.5 K \n",
            "---------------------------------------------------------\n",
            "51.2 M    Trainable params\n",
            "1.1 B     Non-trainable params\n",
            "1.1 B     Total params\n",
            "4,469.943 Total estimated model params size (MB)\n",
            "Validation sanity check: 0it [00:00, ?it/s]/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "Validation sanity check:   0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 23. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "Global seed set to 23\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/808 [00:00<?, ?it/s] \n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:227: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
            "  warning_cache.warn(\n",
            "[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 25. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 18. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 21. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 20. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 22. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 24. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 15. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 19. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "Epoch 0:   2% 20/808 [00:12<07:55,  1.66it/s, loss=0.174, v_num=0, train/loss_simple_step=0.0481, train/loss_vlb_step=0.000174, train/loss_step=0.0481, train/loss_reg_step=2.35e-5, global_step=19.00]\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 27. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:   5% 40/808 [00:22<07:09,  1.79it/s, loss=0.188, v_num=0, train/loss_simple_step=0.153, train/loss_vlb_step=0.000523, train/loss_step=0.153, train/loss_reg_step=1.36e-5, global_step=39.00]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:644: UserWarning: ModelCheckpoint(monitor='val/loss_simple_ema') not found in the returned metrics: ['train/loss_simple', 'train/loss_simple_step', 'train/loss_vlb', 'train/loss_vlb_step', 'train/loss', 'train/loss_step', 'train/loss_reg', 'train/loss_reg_step', 'global_step']. HINT: Did you call self.log('val/loss_simple_ema', value) in the LightningModule?\n",
            "  warning_cache.warn(m)\n",
            "Epoch 0, global step 49: val/loss_simple_ema was not in top 1\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 30. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.66it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:06,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  7.13it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  7.16it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:00<00:06,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:05,  7.18it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  7.17it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  7.18it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  7.19it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  7.19it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  7.21it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:01<00:04,  7.20it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:04,  7.22it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  7.22it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  7.22it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  7.23it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  7.17it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:02<00:04,  7.16it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:03,  7.16it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  7.18it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  7.18it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  7.16it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:03<00:03,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:02,  7.13it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  7.11it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:04<00:02,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:01,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:05<00:01,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:00,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  7.19it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  7.23it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  7.17it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  7.14it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  7.13it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:06<00:00,  7.14it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:06<00:00,  7.15it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:06<05:38,  6.91s/it]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:07<02:21,  2.96s/it]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:07<01:19,  1.69s/it]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:07<00:50,  1.10s/it]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:07<00:34,  1.30it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:07<00:25,  1.75it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:08<00:19,  2.24it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:08<00:15,  2.75it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:08<00:12,  3.25it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:08<00:10,  3.69it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:08<00:09,  4.07it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:08<00:08,  4.39it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:09<00:07,  4.65it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:09<00:07,  4.84it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:09<00:07,  4.98it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:06,  5.08it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:09<00:06,  5.15it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:06,  5.23it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:10<00:05,  5.28it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:10<00:05,  5.30it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:10<00:05,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:10<00:05,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:11<00:05,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:11<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:11<00:04,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:11<00:04,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:11<00:04,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:11<00:04,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:12<00:03,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:12<00:03,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:12<00:03,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:12<00:03,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:12<00:03,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:13<00:02,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:13<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:13<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:13<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:13<00:02,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:13<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:14<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:14<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:14<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:14<00:01,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:14<00:01,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:15<00:00,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:15<00:00,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:15<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:15<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:15<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:16<00:00,  3.12it/s]\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 28. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:   7% 60/808 [01:01<12:44,  1.02s/it, loss=0.204, v_num=0, train/loss_simple_step=0.0158, train/loss_vlb_step=7.21e-5, train/loss_step=0.0158, train/loss_reg_step=3e-5, global_step=59.00]  \n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 29. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  10% 80/808 [01:11<10:52,  1.12it/s, loss=0.0995, v_num=0, train/loss_simple_step=0.173, train/loss_vlb_step=0.000586, train/loss_step=0.173, train/loss_reg_step=3.99e-5, global_step=79.00]\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 26. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  12% 100/808 [01:21<09:40,  1.22it/s, loss=0.0985, v_num=0, train/loss_simple_step=0.079, train/loss_vlb_step=0.000269, train/loss_step=0.079, train/loss_reg_step=1.58e-5, global_step=99.00]Epoch 0, global step 99: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:06,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  7.14it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  7.16it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  7.14it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:00<00:06,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:05,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:01<00:05,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:04,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:02<00:04,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:03<00:03,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:02,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:04<00:02,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:01,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  7.11it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:00,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  7.11it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  7.14it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  7.16it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:06<00:00,  7.17it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  7.06it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:06,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.42it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.42it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:07<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.39it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  15% 120/808 [01:53<10:48,  1.06it/s, loss=0.0589, v_num=0, train/loss_simple_step=0.00268, train/loss_vlb_step=1.62e-5, train/loss_step=0.00269, train/loss_reg_step=1.36e-5, global_step=119.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  17% 140/808 [02:04<09:52,  1.13it/s, loss=0.156, v_num=0, train/loss_simple_step=0.083, train/loss_vlb_step=0.000278, train/loss_step=0.083, train/loss_reg_step=3.41e-5, global_step=139.0]    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0, global step 149: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:08,  5.98it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:07,  6.56it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:07,  6.62it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:07,  6.57it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  6.75it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  6.89it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:03,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:02,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:00,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:06<00:00,  7.02it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  7.00it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.42it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.38it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.36it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  20% 160/808 [02:35<10:29,  1.03it/s, loss=0.176, v_num=0, train/loss_simple_step=0.309, train/loss_vlb_step=0.00127, train/loss_step=0.309, train/loss_reg_step=1.32e-5, global_step=159.0] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  22% 180/808 [02:45<09:38,  1.09it/s, loss=0.236, v_num=0, train/loss_simple_step=0.315, train/loss_vlb_step=0.00161, train/loss_step=0.315, train/loss_reg_step=1.58e-5, global_step=179.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/envs/vico/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "\n",
            "\n",
            "Epoch 0:  25% 200/808 [02:56<08:55,  1.14it/s, loss=0.218, v_num=0, train/loss_simple_step=0.0073, train/loss_vlb_step=3.69e-5, train/loss_step=0.00732, train/loss_reg_step=1.87e-5, global_step=199.0]Epoch 0, global step 199: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.73it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:07,  6.80it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  6.91it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  6.65it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  6.37it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.11it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:05,  6.01it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:05,  5.76it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:05,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:05,  5.74it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.87it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  5.89it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  5.87it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:04,  5.80it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:04,  5.87it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.90it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.96it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:03,  5.98it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.01it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.00it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:03,  5.95it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.86it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.88it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:02,  5.87it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:05<00:02,  5.90it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  5.97it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:02,  6.02it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.98it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:02,  5.95it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  5.80it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:06<00:01,  5.70it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:06<00:01,  5.83it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:07<00:01,  6.41it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:00,  6.61it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:07<00:00,  6.71it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:07<00:00,  6.82it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:07<00:00,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:07<00:00,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  6.96it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  6.25it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.22it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:09,  5.20it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:09,  5.19it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.17it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.17it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:08,  5.25it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:08,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.25it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.30it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:03<00:06,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.41it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.36it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  27% 220/808 [03:28<09:16,  1.06it/s, loss=0.24, v_num=0, train/loss_simple_step=0.597, train/loss_vlb_step=0.00808, train/loss_step=0.597, train/loss_reg_step=1.94e-5, global_step=219.0]    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  30% 240/808 [03:38<08:37,  1.10it/s, loss=0.231, v_num=0, train/loss_simple_step=0.234, train/loss_vlb_step=0.00083, train/loss_step=0.234, train/loss_reg_step=8.74e-6, global_step=239.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0, global step 249: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.86it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:06,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  6.89it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  6.92it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:01,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:00,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  7.03it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  6.97it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:06,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:07<00:01,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.38it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  32% 260/808 [04:09<08:46,  1.04it/s, loss=0.172, v_num=0, train/loss_simple_step=0.00931, train/loss_vlb_step=4.51e-5, train/loss_step=0.00932, train/loss_reg_step=1.32e-5, global_step=259.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  35% 280/808 [04:20<08:11,  1.08it/s, loss=0.163, v_num=0, train/loss_simple_step=0.151, train/loss_vlb_step=0.000507, train/loss_step=0.151, train/loss_reg_step=1.4e-5, global_step=279.0]    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  37% 300/808 [04:30<07:38,  1.11it/s, loss=0.148, v_num=0, train/loss_simple_step=0.242, train/loss_vlb_step=0.000893, train/loss_step=0.242, train/loss_reg_step=1.82e-5, global_step=299.0]Epoch 0, global step 299: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.71it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:07,  6.78it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  6.80it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  6.84it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  6.85it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.80it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.82it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:06,  6.80it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  6.83it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  6.92it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.81it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.85it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  6.92it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  6.91it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  6.96it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  6.84it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  6.92it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:02,  6.86it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  6.86it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  6.84it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  6.84it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.91it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:01,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  6.97it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  6.98it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  6.92it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:08,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:06,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.33it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.37it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  40% 320/808 [05:02<07:41,  1.06it/s, loss=0.105, v_num=0, train/loss_simple_step=0.0232, train/loss_vlb_step=9.81e-5, train/loss_step=0.0232, train/loss_reg_step=1.62e-5, global_step=319.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  42% 340/808 [05:12<07:10,  1.09it/s, loss=0.102, v_num=0, train/loss_simple_step=0.462, train/loss_vlb_step=0.00613, train/loss_step=0.462, train/loss_reg_step=2.54e-5, global_step=339.0]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0, global step 349: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:06,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:06,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  6.84it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  6.89it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.89it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.92it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  6.91it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.91it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  6.86it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  6.68it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  6.56it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  6.49it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.45it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:04,  6.50it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:04,  6.44it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  6.41it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  6.50it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:03,  6.50it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.40it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.33it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:03,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:03,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:03,  5.91it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:02,  6.07it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  6.52it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:02,  6.65it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  6.76it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  6.78it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  6.82it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:06<00:01,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:06<00:01,  6.58it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.35it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:01,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:07<00:00,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:07<00:00,  6.05it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:07<00:00,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  6.24it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  6.54it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:10,  4.60it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:10,  4.49it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:10,  4.66it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:09,  4.92it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:01<00:08,  5.08it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.18it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:08,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.27it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.31it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:03<00:06,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.18it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:06,  5.05it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:06,  5.01it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:06,  4.96it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:04<00:05,  4.90it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  4.86it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  4.80it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:05,  4.88it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:05,  4.90it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:05<00:04,  4.92it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  4.96it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  4.98it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:04,  4.91it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:04,  4.89it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:06<00:03,  4.87it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:06<00:03,  5.01it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.12it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:03,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.27it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:07<00:02,  5.32it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:07<00:02,  5.34it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.32it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:08<00:01,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:08<00:01,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:09<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:09<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.17it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  45% 360/808 [05:44<07:08,  1.04it/s, loss=0.206, v_num=0, train/loss_simple_step=0.0498, train/loss_vlb_step=0.000182, train/loss_step=0.0498, train/loss_reg_step=3.5e-5, global_step=359.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  47% 380/808 [05:55<06:40,  1.07it/s, loss=0.291, v_num=0, train/loss_simple_step=0.288, train/loss_vlb_step=0.00154, train/loss_step=0.288, train/loss_reg_step=1.1e-5, global_step=379.0]   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  50% 400/808 [06:05<06:12,  1.09it/s, loss=0.126, v_num=0, train/loss_simple_step=0.342, train/loss_vlb_step=0.0017, train/loss_step=0.342, train/loss_reg_step=2.09e-5, global_step=399.0]Epoch 0, global step 399: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.94it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:06,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:00<00:06,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:01<00:05,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:04,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  7.14it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:02<00:04,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:03,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:03<00:03,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:02,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:04<00:02,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:01,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:01,  6.69it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  6.78it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  6.87it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  6.93it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:06<00:00,  7.00it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  7.03it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.26it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.29it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.32it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:08,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.25it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.17it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.10it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.19it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:07,  5.25it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.26it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:03<00:06,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.17it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:06,  5.16it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.27it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.30it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:06<00:03,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:09<00:00,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.41it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.33it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  52% 420/808 [06:37<06:06,  1.06it/s, loss=0.202, v_num=0, train/loss_simple_step=0.265, train/loss_vlb_step=0.00134, train/loss_step=0.265, train/loss_reg_step=1.13e-5, global_step=419.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  54% 440/808 [06:47<05:40,  1.08it/s, loss=0.13, v_num=0, train/loss_simple_step=0.386, train/loss_vlb_step=0.00186, train/loss_step=0.386, train/loss_reg_step=7.53e-6, global_step=439.0] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0, global step 449: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:06,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:06,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:00<00:06,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:05,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:01<00:05,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:04,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:02<00:04,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:03,  7.03it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  6.88it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  6.84it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  6.84it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  6.91it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:03<00:03,  6.99it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:02,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  7.14it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  7.12it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:04<00:02,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:01,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  7.11it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:05<00:01,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:00,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  6.65it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  6.75it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:06<00:00,  6.84it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  7.01it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.42it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.42it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.28it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:07,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.18it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.19it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:03<00:06,  5.19it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.16it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:06,  5.13it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:06,  5.14it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.12it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.11it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.08it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.15it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:05,  5.14it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.11it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.13it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.27it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.30it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.32it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:07<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:09<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.40it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.31it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  57% 460/808 [07:18<05:31,  1.05it/s, loss=0.178, v_num=0, train/loss_simple_step=0.371, train/loss_vlb_step=0.00183, train/loss_step=0.371, train/loss_reg_step=1.67e-5, global_step=459.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  59% 480/808 [07:28<05:06,  1.07it/s, loss=0.183, v_num=0, train/loss_simple_step=0.0289, train/loss_vlb_step=0.000116, train/loss_step=0.0289, train/loss_reg_step=1.13e-5, global_step=479.0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 0:  62% 500/808 [07:38<04:42,  1.09it/s, loss=0.181, v_num=0, train/loss_simple_step=0.0169, train/loss_vlb_step=7.61e-5, train/loss_step=0.0169, train/loss_reg_step=2.71e-5, global_step=499.0] Epoch 0, global step 499: val/loss_simple_ema was not in top 1\n",
            "\n",
            "pop from empty list\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.85it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:06,  6.90it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:06,  6.95it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:06,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:06,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:06,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  7.02it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:05,  7.01it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:05,  6.89it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:05,  6.91it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:05,  6.98it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:05,  7.05it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:01<00:05,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:01<00:05,  7.13it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:04,  7.15it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:04,  7.17it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:04,  7.17it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:04,  7.13it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:02<00:04,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:02<00:04,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:02<00:04,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:03,  7.11it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:03,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:03,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:03<00:03,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:03<00:03,  7.00it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:03<00:03,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:03<00:03,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:02,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:02,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:02,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:04<00:02,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:04<00:02,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:01,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:05<00:01,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:05<00:01,  7.10it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:05<00:01,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:05<00:01,  7.09it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:00,  7.11it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:06<00:00,  7.06it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:06<00:00,  7.04it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:06<00:00,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:06<00:00,  7.07it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:06<00:00,  7.08it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:06<00:00,  7.09it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:07<00:00,  7.06it/s]\n",
            "torch.Size([1, 4, 64, 64])\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:09,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.41it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.39it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:08,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:02<00:07,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:07,  5.25it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:07,  5.23it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.28it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.26it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:03<00:06,  5.25it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:06,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:06,  5.22it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:06,  5.12it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.04it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:04<00:05,  5.08it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:05,  5.17it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:05,  5.23it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.23it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.27it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.29it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.28it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:04,  5.30it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.14it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:06<00:03,  5.08it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.15it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:03,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.26it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.30it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:07<00:02,  5.32it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.31it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:02,  5.33it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.35it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.32it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.32it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.16it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.12it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.10it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.18it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:09<00:00,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.28it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.26it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Average Epoch time: 484.98 seconds\n",
            "Average Peak memory 32581.32MiB\n",
            "Epoch 0:  64% 520/808 [08:05<04:28,  1.07it/s, loss=0.177, v_num=0, train/loss_simple_step=0.00741, train/loss_vlb_step=3.78e-5, train/loss_step=0.00745, train/loss_reg_step=3.84e-5, global_step=509.0, train/loss_simple_epoch=0.170, train/loss_vlb_epoch=0.00328, train/loss_epoch=0.170, train/loss_reg_epoch=2.32e-5]\n",
            "Saving latest checkpoint...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hj86VbmykVYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps for running the below inference script:\n",
        "IMAGE-PATH: path to a reference image.\n",
        "\n",
        "CHECKPOINTS-PATH: path containing the folder checkpoints (the embeddings after the training).\n",
        "\n",
        "TEXT-PROMPT: your desired text prompt.\n",
        "\n",
        "OUTPUT-DIR: path to the folder in which you want the generated images to be saved. (eg. outputs/dog)\n",
        "\n",
        "**Running inference, given a text prompt and a reference image**"
      ],
      "metadata": {
        "id": "ArYR68Nj9Ftf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /usr/local/bin/activate vico && python scripts/vico_model.py \\\n",
        "--ddim_eta 0.0  --n_samples 4  --n_iter 2  --scale 7.5  --ddim_steps 50  \\\n",
        "--ckpt_path models/stable-diffusion-v1/sd-v1-4.ckpt  \\\n",
        "--image_path images/ollie/1.png \\\n",
        "--ft_path logs/ollie2024-03-12T18-36-55_v1-finetune \\\n",
        "--load_step 399 \\\n",
        "--prompt \"A photo of a * with iridescent wings, soaring through a starry night sky filled with constellations\" \\\n",
        "--outdir outputs/ollie-399"
      ],
      "metadata": {
        "id": "JucvYbqI5nVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c39707-682e-420c-924a-43c5d630b3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 42\n",
            "cross attention path: logs/ollie2024-03-12T18-36-55_v1-finetune/checkpoints/cross_attention-399.pt\n",
            "embedding path: logs/ollie2024-03-12T18-36-55_v1-finetune/checkpoints/embeddings_gs-399.pt\n",
            "Loading model from models/stable-diffusion-v1/sd-v1-4.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 910.77 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'logit_scale', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'visual_projection.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'text_projection.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "CLIP text encoder Total:123.06M Trainable:0.00M\n",
            "UNet + ImageCA Total:910.77M Trainable:51.25M\n",
            "Embedding manager Total:0.00M Trainable:0.00M\n",
            "Sampling:   0% 0/2 [00:00<?, ?it/s]Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:29,  1.64it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:28,  1.68it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:01<00:27,  1.69it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:02<00:27,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:02<00:26,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:03<00:25,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:04<00:25,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:04<00:24,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:05<00:24,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:05<00:23,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:06<00:22,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:07<00:22,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:07<00:21,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:08<00:21,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:08<00:20,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:19,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:10<00:19,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:18,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:11<00:18,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:11<00:17,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:12<00:17,  1.69it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:12<00:16,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:13<00:15,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:14<00:15,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:14<00:14,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:15<00:14,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:15<00:13,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:16<00:12,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:17<00:12,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:17<00:11,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:18<00:11,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:18<00:10,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:19<00:09,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:19<00:09,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:20<00:08,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:21<00:08,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:21<00:07,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:22<00:07,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:22<00:06,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:23<00:05,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:24<00:05,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:24<00:04,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:25<00:04,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:25<00:03,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:26<00:02,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:27<00:02,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:27<00:01,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:28<00:01,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:28<00:00,  1.70it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:29<00:00,  1.70it/s]\n",
            "Sampling:  50% 1/2 [00:29<00:29, 29.85s/it]Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:28,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:28,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:01<00:27,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:02<00:27,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:02<00:26,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:03<00:25,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:04<00:25,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:04<00:24,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:05<00:24,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:05<00:23,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:06<00:22,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:07<00:22,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:07<00:21,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:08<00:21,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:08<00:20,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:19,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:09<00:19,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:18,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:11<00:18,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:11<00:17,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:12<00:17,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:12<00:16,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:13<00:15,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:14<00:15,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:14<00:14,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:15<00:14,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:15<00:13,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:16<00:12,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:17<00:12,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:17<00:11,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:18<00:11,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:18<00:10,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:19<00:09,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:19<00:09,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:20<00:08,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:21<00:08,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:21<00:07,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:22<00:07,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:22<00:06,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:23<00:05,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:24<00:05,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:24<00:04,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:25<00:04,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:25<00:03,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:26<00:02,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:27<00:02,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:27<00:01,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:28<00:01,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:28<00:00,  1.70it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:29<00:00,  1.70it/s]\n",
            "Sampling: 100% 2/2 [00:59<00:00, 29.79s/it]\n",
            "Your samples are ready and waiting four you here: \n",
            "outputs/ollie-399 \n",
            "Enjoy.\n"
          ]
        }
      ]
    }
  ]
}